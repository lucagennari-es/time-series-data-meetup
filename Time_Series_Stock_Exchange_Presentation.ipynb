{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')\n",
    "\n",
    "start = dt.datetime(2000, 1, 1)\n",
    "end = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df = web.DataReader(\"TSLA\", 'yahoo', start, end)\n",
    "elastic_df = web.DataReader(\"ESTC\", 'yahoo', start, end)\n",
    "netflix_df = web.DataReader(\"NFLX\", 'yahoo', start, end)\n",
    "okta_df = web.DataReader(\"OKTA\", 'yahoo', start, end)\n",
    "nasdaq_df = web.DataReader(\"NDAQ\", 'yahoo', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.reset_index(inplace=True)\n",
    "tesla_df.set_index(\"Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df['Adj Close'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df[['High','Low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the median average at 60 times\n",
    "tesla_df['moving_average'] = tesla_df['Adj Close'].rolling(window=60, min_periods=0).mean()\n",
    "elastic_df['moving_average'] = elastic_df['Adj Close'].rolling(window=60, min_periods=0).mean()\n",
    "netflix_df['moving_average'] = netflix_df['Adj Close'].rolling(window=60, min_periods=0).mean()\n",
    "okta_df['moving_average'] = okta_df['Adj Close'].rolling(window=60, min_periods=0).mean()\n",
    "nasdaq_df['moving_average'] = nasdaq_df['Adj Close'].rolling(window=60, min_periods=0).mean()\n",
    "\n",
    "\n",
    "# add the symbol info\n",
    "tesla_df['symbol'] = \"TSLA\"\n",
    "elastic_df['symbol'] = \"ESTC\"\n",
    "netflix_df['symbol'] = \"NFLX\"\n",
    "okta_df['symbol'] = \"OKTA\"\n",
    "nasdaq_df['symbol'] = \"NDAQ\"\n",
    "\n",
    "\n",
    "# add name\n",
    "tesla_df['name'] = \"Tesla, Inc.\"\n",
    "elastic_df['name'] = \"Elastic NV\"\n",
    "netflix_df['name'] = \"Netflix, Inc.\"\n",
    "okta_df['name'] = \"Okta, Inc.\"\n",
    "nasdaq_df['name'] = \"Nasdaq, Inc.\"\n",
    "\n",
    "\n",
    "# add description\n",
    "# add name\n",
    "tesla_df['description'] = \"Tesla, Inc. (formerly Tesla Motors, Inc.), is an American electric vehicle and clean energy company based in Palo Alto, California.\"\n",
    "elastic_df['description'] = \"Elasticsearch is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents. Elasticsearch is developed in Java.\"\n",
    "netflix_df['description'] = \"Netflix, Inc. is an American media-services provider and production company headquartered in Los Gatos, California, founded in 1997 by Reed Hastings and Marc Randolph in Scotts Valley, California.\"\n",
    "okta_df['description'] = \"Okta, Inc. is a publicly traded identity and access management company based in San Francisco. It provides cloud software that helps companies manage and secure user authentication into modern applications, and for developers to build identity controls into applications, website web services and devices. It was founded in 2009 and had its initial public offering in 2017, being valued at over $6 billion.\"\n",
    "nasdaq_df['description'] = \"Nasdaq, Inc. is an American multinational financial services corporation that owns and operates (and is listed on) the Nasdaq stock market and eight European Stock Exchanges, including the Armenian Stock Exchange, Copenhagen Stock Exchange, Helsinki Stock Exchange, Iceland Stock Exchange, Riga Stock Exchange, Stockholm Stock Exchange, Tallinn Stock Exchange, and NASDAQ OMX Vilnius. It is headquartered in New York City, and its president and chief executive officer is Adena Friedman.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot2grid((6,1), (0,0), rowspan=5, colspan=1)\n",
    "ax2 = plt.subplot2grid((6,1), (5,0), rowspan=1, colspan=1, sharex=ax1)\n",
    "\n",
    "ax1.plot(tesla_df.index, tesla_df['Adj Close'])\n",
    "ax1.plot(tesla_df.index, tesla_df['moving_average'])\n",
    "ax2.bar(tesla_df.index, tesla_df['Volume'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df.head()\n",
    "nasdaq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_csv(\"data/tesla_df.csv\")\n",
    "elastic_df.to_csv(\"data/elastic_df.csv\")\n",
    "netflix_df.to_csv(\"data/netflix_df.csv\")\n",
    "okta_df.to_csv(\"data/okta_df.csv\")\n",
    "nasdaq_df.to_csv(\"data/nasdaq_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elastic_df.shape)\n",
    "print(netflix_df.shape)\n",
    "print(tesla_df.shape)\n",
    "print(okta_df.shape)\n",
    "print(nasdaq_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfor data to elastic documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_space(iterator):\n",
    "    return itertools.chain([next(iterator).replace(\" \", \"_\").lower()], iterator)\n",
    "# replace \" \" with _ and lowercase field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the name of the csv file where to get data and the name for the index\n",
    "csv_file_h = \"data/nasdaq_df.csv\"\n",
    "index_name = \"nasdaq_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "with open(csv_file_h) as csv_file:\n",
    "    # replace a blank space with an underscore\n",
    "    csv_file = lower_space(csv_file)\n",
    "    \n",
    "    csvReader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in csvReader:\n",
    "        for item in row:\n",
    "            if row[item].isdigit():\n",
    "                row[item] = int(row[item])\n",
    "             \n",
    "            if item != 'date' and item != 'description' and item != 'symbol' and item != 'name':\n",
    "                row[item] = float(row[item])\n",
    "            \n",
    "        data_list.append(dict(row))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following option generate a bulk ready json file (skip if not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_header = '{\"index\": {\"_index\": \"' + index_name + '\"}}'\n",
    "\n",
    "with open('data/nasdaq_data.json', 'w') as bulk_file:\n",
    "    for x in data_list:\n",
    "        my_dict = {k:v for k, v in x.items()}\n",
    "        bulk_file.write(my_header + '\\n' + json.dumps(my_dict) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following option insert data directly to elasticsearch\n",
    "## 1 - create mapping\n",
    "## 2 - create elasticsearch client\n",
    "## 3 - create index and upload data in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_mapping = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"date\": {\n",
    "        \"type\": \"date\"\n",
    "      },\n",
    "      \"high\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"low\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"open\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"close\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"adj_close\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"volume\": {\n",
    "        \"type\": \"integer\"\n",
    "      },\n",
    "        \"moving_average\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"description\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"symbol\": {\n",
    "          \"type\": \"keyword\"\n",
    "      },\n",
    "      \"name\": {\n",
    "          \"type\": \"text\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send on cloud\n",
    "#es = Elasticsearch(\n",
    "#    cloud_id=\"your_id:alphanumeric_token_provided_by_elastic_cloud\",\n",
    "#    http_auth=(\"elastic\", \"your_amazing_password\"),\n",
    "#)\n",
    "\n",
    "# connection parameters\n",
    "host = \"localhost\"\n",
    "port = 9200\n",
    "user = \"\"\n",
    "pawd = \"\"\n",
    "ssl_context = \"\"\n",
    "\n",
    "# elasticsearch client\n",
    "es = Elasticsearch(hosts=[{'host': host, 'port': port}], scheme=\"http\") #ssl_context=ssl_context, http_auth=(user, pawd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"nasdaq_index\"\n",
    "\n",
    "# delete old index if exists\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "\n",
    "# create index with mapping\n",
    "r = es.indices.create(index=index_name, body=ticker_mapping)\n",
    "print(r)\n",
    "\n",
    "## load in elasticsearch (bulk)\n",
    "helpers.bulk(es, actions=data_list, index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine together all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = pd.concat( [ pd.read_csv(f) for f in [\"data/tesla_df.csv\", \"data/elastic_df.csv\", \"data/netflix_df.csv\", \"data/okta_df.csv\", \"data/nasdaq_df.csv\"] ] )\n",
    "combined_csv.to_csv( \"data/combined_tickers.csv\", index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "csv_file_h = \"data/combined_tickers.csv\"\n",
    "\n",
    "with open(csv_file_h) as csv_file:\n",
    "    # replace a blank space with an underscore\n",
    "    csv_file = lower_space(csv_file)\n",
    "    \n",
    "    csvReader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in csvReader:\n",
    "        for item in row:\n",
    "            if row[item].isdigit():\n",
    "                row[item] = int(row[item])\n",
    "             \n",
    "            if item != 'date' and item != 'description' and item != 'symbol' and item != 'name':\n",
    "                row[item] = float(row[item])\n",
    "            \n",
    "        data_list.append(dict(row))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"indeces_combined\"\n",
    "\n",
    "# delete old index if exists\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "\n",
    "# create index with mapping\n",
    "r = es.indices.create(index=index_name, body=ticker_mapping)\n",
    "print(r)\n",
    "\n",
    "## load in elasticsearch (bulk)\n",
    "helpers.bulk(es, actions=data_list, index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earning Calendar Association (from Yahoo Finance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * BMO — before the market opens\n",
    "### * AMC — after the market closes\n",
    "### * TAS/TNS — time not specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_earnings_calendar import YahooEarningsCalendar\n",
    "from datetime import timedelta\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just clean the data frame is exists, not really needed\n",
    "#del earnings_df\n",
    "\n",
    "# Ticker from which download earnings list\n",
    "TICKER = 'NFLX'\n",
    "\n",
    "# next list of earnings (to be released in future dates)\n",
    "DAYS_EARNINGS_AHEAD = 3650\n",
    "\n",
    "# setting the dates:\n",
    "start_date = start # start is set up above on box In[2]\n",
    "end_date = (end + timedelta(days=DAYS_EARNINGS_AHEAD))\n",
    "\n",
    "# downloading the earnings calendar\n",
    "yec = YahooEarningsCalendar()\n",
    "\n",
    "earnings_list = yec.get_earnings_of(TICKER)\n",
    "earnings_df = pd.DataFrame(earnings_list)\n",
    "\n",
    "earnings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df = earnings_df.drop(columns=[\"gmtOffsetMilliSeconds\"])\n",
    "\n",
    "print(earnings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df.rename(columns={\"ticker\": \"symbol\", \n",
    "                            \"companyshortname\": \"name\", \n",
    "                            \"startdatetime\": \"date\", \n",
    "                            \"startdatetimetype\": \"type\",\n",
    "                            \"epsestimate\": \"estimate\",\n",
    "                            \"epsactual\": \"reported\",\n",
    "                            \"epssurprisepct\": \"surprise\",\n",
    "                            \"quoteType\": \"quote\"}, inplace=True)\n",
    "\n",
    "# convert all NaN to 0.0\n",
    "earnings_df[\"estimate\"] = earnings_df[\"estimate\"].fillna(0.0)\n",
    "earnings_df[\"reported\"] = earnings_df[\"reported\"].fillna(0.0)\n",
    "earnings_df[\"surprise\"] = earnings_df[\"surprise\"].fillna(0.0)\n",
    "\n",
    "earnings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "earnings_df.reset_index(drop=True, inplace=True)\n",
    "earnings_df.set_index(\"date\", inplace=True)\n",
    "\n",
    "earnings_df.to_csv(\"data/netflix_earning_index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_mapping = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"date\": {\n",
    "        \"type\": \"date\"\n",
    "      },\n",
    "      \"type\": {\n",
    "        \"type\": \"keyword\"\n",
    "      },\n",
    "      \"estimate\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"reported\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"surprise\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"quote\": {\n",
    "        \"type\": \"keyword\"\n",
    "      },\n",
    "      \"symbol\": {\n",
    "          \"type\": \"keyword\"\n",
    "      },\n",
    "      \"name\": {\n",
    "          \"type\": \"text\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "csv_file_h = \"data/netflix_earning_index.csv\"\n",
    "\n",
    "with open(csv_file_h) as csv_file:\n",
    "    # replace a blank space with an underscore\n",
    "    csv_file = lower_space(csv_file)\n",
    "    \n",
    "    csvReader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in csvReader:\n",
    "        for item in row:\n",
    "            if item != 'date' and item != 'type' and item != 'symbol' and item != 'name' and item != 'quote':\n",
    "                row[item] = float(row[item])\n",
    "            \n",
    "        data_list.append(dict(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"netflix_earning_index\"\n",
    "\n",
    "# delete old index if exists\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "\n",
    "# create index with mapping\n",
    "r = es.indices.create(index=index_name, body=earnings_mapping)\n",
    "print(r)\n",
    "\n",
    "## load in elasticsearch (bulk)\n",
    "helpers.bulk(es, actions=data_list, index=index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
